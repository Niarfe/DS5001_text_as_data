2026-02-04 16:03:54 -0800

# FREEZEDOWN Snapshot

## What went wrong last time (failure analysis)
The previous output used a single outer triple-backtick code fence *and* also contained inner triple-backtick fences for Python snippets. In Markdown, triple-backticks **cannot be nested**: the first inner ``` closed the outer fence early, so the rest of the content rendered as normal text.

Fix: Use **one outer triple-backtick fence** for the whole artifact, and use **tildes (`~~~`)** for any inner code blocks so nothing prematurely closes.

---

## What this chat covered
This conversation centered on **Exploratory Text Analysis (ETA)** concepts and **digital humanities / cultural analytics** readings, then shifted into **practical pandas workflows** for building and combining OHCO-structured token dataframes in Jupyter.

## Key reading summaries completed

### “Word Play” (Nature, 2011) — culturomics + Google N-Gram Viewer
- Culturomics applies large-scale quantitative analysis to digitized books (e.g., Google Books n-grams) to detect cultural and linguistic change over time.
- Strengths: scale, pattern discovery. Limits: corpus bias, frequency ≠ meaning, culture extends beyond text.

### Lev Manovich (2016) — “The Science of Culture? … Cultural Analytics”
- Cultural analytics bridges and expands beyond:
  - **Digital humanities** (often historical + professional artifacts)
  - **Social computing** (often post-2004 social media scale + CS framing)
- Advocates combining humanistic interpretation with scientific modeling.
- Key notions: “content islands,” general vs particular, probabilistic models, and “wide data” (many features per artifact/user).

### Paul Ricœur (1973) — “The Model of the Text: Meaningful Action Considered as a Text”
- Four traits of text (text as utterance fixed by writing):
  1. Fixation of meaning  
  2. Detachment from author’s intention  
  3. Shift from ostensive reference to world-projection  
  4. Universal address (open audience)
- Extends text-model to meaningful action (actions leave traces, detach from agents, gain transcontextual relevance, remain open to interpretation).
- Explains **Erklären** and **Verstehen** as a dialectic (guess + validation; structural explanation enabling deeper understanding).

## Quiz / concept checks answered
- ETA influences: IR, NLP, Text Mining, Digital Humanities → **All of the above**.
- ETA uses mainly **unsupervised** ML methods.
- Premise that texts “contain” discoverable cultural patterns → **True** (with nuance: methods shape visibility).
- Long-form texts: novels, newspapers, blog posts → **not tweets**.
- Google N-Gram school of thought: **culturomics**.
- Saussure: langue/parole glossed as grammar + **usage**; in DH/hermeneutics framing, parole aligns more precisely with **discourse** (usage is looser).
- Hermeneutics definition (interpreting historically distant texts like Bible/Roman law): **hermeneutics**.
- Ricœur: four text traits guiding interpretation → **True**.
- XML’s text model: **hierarchical / tree model**.
- Ricœur/Benveniste: elementary unit of discourse = **sentence** (French: **phrase**).
- Clarified English “phrase” ≠ French *phrase*: French *phrase* corresponds to English *sentence* in linguistics.

## OHCO clarified (assignment context)
- **OHCO** = **Ordered Hierarchy of Content Objects**.
- Encodes a nested text structure for analysis, e.g.:
  - Book → Chapter → Paragraph → Sentence → Token
- Assignment requirement: include chapters/paragraphs/sentences in dataframe index; when combining two novels, add a **book title** level.

## pandas / Jupyter workflow solved

### Add a new column first in order
~~~python
df['D'] = 5
df = df[['D','A','B','C']]
~~~

### Get column names as list of strings
~~~python
list(df.columns)
~~~

### MultiIndex “sparse display” vs actual data
- Jupyter’s HTML display hides repeated MultiIndex labels; CSV makes them explicit.
- In-memory equivalent of CSV round-trip:
~~~python
df = df.reset_index()
# or
df.reset_index(inplace=True)
~~~

### Combine two token dataframes by stacking rows
~~~python
df = pd.concat([df1, df2], ignore_index=True)
~~~

### Avoid unwanted `"index"` column after concat
~~~python
df1 = df1.drop(columns=['index'])
df2 = df2.drop(columns=['index'])
df = pd.concat([df1, df2], ignore_index=True)
~~~

## Jupyter notebook scrolling issue
- Scroll “jerks/jumps,” then becomes smooth after repeated scrolling.
- Likely cause: browser reflow / deferred rendering from large HTML outputs.
- Mitigations: limit displayed rows, use `to_string()`, clear/collapse outputs, restart & clear output, try a different browser.

## Current state
- Two dataframes (current + CSV-loaded) are now in the desired flat-column form.
- They have been concatenated successfully, with the spurious `"index"` column removed.

## Open threads / next steps
- Add / verify a **book title** level in OHCO when combining *Persuasion* + *Sense and Sensibility*.
- Decide final indexing strategy:
  - keep flat columns, or
  - set MultiIndex: `['book', 'chap_num', 'para_num', 'sent_num', 'token_num']`.
- Adopt output practices to reduce scroll-jank in Jupyter.
